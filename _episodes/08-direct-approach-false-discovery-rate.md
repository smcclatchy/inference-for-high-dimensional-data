---
# Please do not edit this file directly; it is auto generated.
# Instead, please edit 08-direct-approach-false-discovery-rate.md in _episodes_rmd/
source: Rmd
title: "Direct Approach to FDR and q-values"
teaching: 0
exercises: 0
questions:
- "What are multiple comparisons?"
- "Why are multiple comparisons a problem when drawing inferences from high-throughput data?"
- "How we can we address the multiple comparisons problem?"
objectives:
- "Define multiple comparisons and the resulting problems."
- "Describe two ways to deal with multiple comparisons."
keypoints:
- "..."
- "..."
---

## Direct Approach to FDR and q-values (Advanced)

Here we review the results described by John D. Storey in J. R. Statist. Soc. B (2002). One major distinction between Storey's approach and Benjamini and Hochberg's is that we are no longer going to set a $\alpha$ level a priori. Because in many high-throughput experiments we are interested in obtaining some list for validation, we can instead decide beforehand that we will consider all tests with p-values smaller than 0.01. We then want to attach an estimate of an error rate. Using this approach, we are guaranteed to have $R>0$. Note that in the FDR definition above we assigned $Q=0$ in the case that $R=V=0$. We were therefore computing: 

$$
\mbox{FDR} = E\left( \frac{V}{R} \mid R>0\right) \mbox{Pr}(R>0)
$$

In the approach proposed by Storey, we condition on having a non-empty list, which implies $R>0$, and we instead compute the _positive FDR_ 

$$
\mbox{pFDR} = E\left( \frac{V}{R} \mid R>0\right) 
$$

A second distinction is that while Benjamini and Hochberg's procedure controls under the worst case scenario, in which all null hypotheses are true ( $m=m_0$ ), Storey proposes that we actually try to estimate $m_0$ from the data. Because in high-throughput experiments we have so much data, this is certainly possible. The general idea is to pick a relatively high value p-value cut-off, call it $\lambda$, and assume that tests obtaining p-values > $\lambda$ are mostly from cases in which the null hypothesis holds. We can then estimate $\pi_0 = m_0/m$ as: 

$$
\hat{\pi}_0 = \frac{\#\left\{p_i > \lambda \right\} }{ (1-\lambda) m }
$$

There are more sophisticated procedures than this, but they follow the same general idea. Here is an example setting $\lambda=0.1$. Using the p-values computed above we have:


```r
# re-create p-values from earlier if needed
alpha <- 0.05
B <- 1000 ##number of simulations. We should increase for more precision 
res <- replicate(B, {
  controls <- matrix(sample(population, N*m, replace=TRUE),nrow=m)
  treatments <- matrix(sample(population, N*m, replace=TRUE),nrow=m)
  treatments[which(!nullHypothesis),]<-treatments[which(!nullHypothesis),]+delta 
  dat <- cbind(controls,treatments)
  pvals <- rowttests(dat,g)$p.value
  ##then the FDR
  calls <- p.adjust(pvals,method="fdr") < alpha
  R=sum(calls)
  Q=ifelse(R>0,sum(nullHypothesis & calls)/R,0)
  return(c(R,Q))
  }
  )
```

```
## Error in sample(population, N * m, replace = TRUE): object 'population' not found
```

```r
Qs <- res[2,]
```

```
## Error in eval(expr, envir, enclos): object 'res' not found
```


```r
hist(pvals,breaks=seq(0,1,0.05),freq=FALSE)
```

```
## Error in hist(pvals, breaks = seq(0, 1, 0.05), freq = FALSE): object 'pvals' not found
```

```r
lambda = 0.1
pi0=sum(pvals> lambda) /((1-lambda)*m)
```

```
## Error in eval(expr, envir, enclos): object 'pvals' not found
```

```r
abline(h= pi0)
```

```
## Error in int_abline(a = a, b = b, h = h, v = v, untf = untf, ...): object 'pi0' not found
```

```r
print(pi0) ##this is close to the trye pi0=0.9
```

```
## Error in print(pi0): object 'pi0' not found
```

With this estimate in place we can, for example, alter the Benjamini and Hochberg procedures to select the $k$ to be the largest value so that: 

$$\hat{\pi}_0 p_{(i)} \leq \frac{i}{m}\alpha$$

However, instead of doing this, we compute a _q-value_ for each test. If a feature resulted in a p-value of $p$, the q-value is the estimated pFDR for a list of all the features with a p-value at least as small as $p$.

In R, this can be computed with the `qvalue` function in the `qvalue` package:


```r
library(qvalue)
res <- qvalue(pvals)
```

```
## Error in qvalue(pvals): object 'pvals' not found
```

```r
qvals <- res$qvalues
```

```
## Error in eval(expr, envir, enclos): object 'res' not found
```

```r
plot(pvals, qvals)
```

```
## Error in plot(pvals, qvals): object 'pvals' not found
```

we also obtain the estimate of $\hat{\pi}_0$:


```r
res$pi0
```

```
## Error in eval(expr, envir, enclos): object 'res' not found
```
This function uses a more sophisticated approach at estimating $\pi_0$ than what is described above.

#### Note on estimating $\pi_0$
In our experience the estimation of $\pi_0$ can be unstable and adds a step of uncertainty to the data analysis pipeline. Although more conservative, the Benjamini-Hochberg procedure is computationally more stable. 

## Exercises
In the following exercises, we will define error controlling procedures for 
experimental data. We will make a list of genes based on q-values. We will also 
assess your understanding of false positives rates and false negative rates by 
asking you to create a Monte Carlo simulation.

> ## Exercise 1
> Load the gene expression data:  
> `library(GSE5859Subset)`  
> `data(GSE5859Subset)`  
> We are interested in comparing gene expression between the two groups defined 
> in the sampleInfo table.
> Compute a p-value for each gene using the function `rowttests` from the 
> genefilter package. 
> 
> `library(genefilter)`
> `?rowttests`
> 
> How many genes have p-values smaller than 0.05?
> 
> > ## Solution
> > 
> {: .solution}
{: .challenge}

> ## Exercise 2
> Apply the Bonferroni correction to achieve a FWER of 0.05. How many genes are 
> called significant under this procedure?
> 
> > ## Solution
> > 
> {: .solution}
{: .challenge}

> ## Exercise 3
> The FDR is a property of a list of features, not each specific feature. The
> q-value relates FDR to individual features. To define the q-value, we order 
> features we tested by p-value, then compute the FDRs for a list with the most 
> significant, the two most significant, the three most significant, etc. The 
> FDR of the list with the, say, m most significant tests is defined as the 
> q-value of the m-th most significant feature. In other words, the q-value of a 
> feature, is the FDR of the biggest list that includes that gene.
> In R, we can compute q-values using the p.adjust function with the FDR option. 
> Read the help file for p.adjust and compute how many genes achieve a q-value < 
> 0.05 for our gene expression dataset.
> 
> > ## Solution
> > 
> {: .solution}
{: .challenge}

> ## Exercise 4
> Now use the qvalue function, in the Bioconductor qvalue package, to estimate 
> q-values using the procedure described by Storey. How many genes have q-values 
> below 0.05?
> 
> > ## Solution
> > 
> {: .solution}
{: .challenge}

> ## Exercise 5
> Read the help file for qvalue and report the estimated proportion of genes for 
> which the null hypothesis is true Ï€0 = m0/m
> 
> > ## Solution
> > 
> {: .solution}
{: .challenge}
